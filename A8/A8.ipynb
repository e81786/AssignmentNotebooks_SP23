{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396b2be2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"A8.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d89130",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-68f2f0ed9883b594",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 8\n",
    "\n",
    "\n",
    "## **Due: June 2nd (Friday), 2023, 8:00pm (PT)**\n",
    "\n",
    "### **Instructions:**\n",
    "\n",
    "Your Jupyter notebook assignment will often have 3 elements: written answers, code answers, and quiz answers. For written answers, you may insert images of your handwritten work in code cells, or write your answers in markdown and LaTeX. For quiz answers, your `record.txt` file will record your answer choices in the quiz modules for submission. Both your quiz answers and code answers will be autograded on Gradescope. This assignment does not have the quiz portion.\n",
    "\n",
    "For all elements, DO NOT MODIFY THE CELLS. Put your answers **only** in the answer cells given, and **do not delete cells**. If you fail to follow these instructions, you will lose points on your submission.\n",
    "\n",
    "Make sure to show the steps of your solution for every question to receive credit, not just the final answer. You may search information online but you will need to write code/find solutions to answer the questions yourself. You will submit your .ipynb file and record.txt to gradescope when you are finished.\n",
    "\n",
    "### **Late Policy:**\n",
    "\n",
    "Late assignments will be accepted at 75% credit up to 3 days late. Consult the syllabus for more info on the late policy.\n",
    "\n",
    "### How to Include Your Math Written Answer?\n",
    "\n",
    "You could use inline $\\LaTeX$ in markdown (recommended) or use markdowns' include image functionality to submit your written responses.\n",
    "\n",
    "#### $\\LaTeX$ (recommended)\n",
    "[Here is a fantastic tutorial from CalTech about using $\\LaTeX$ in Jupyter Notebook.](http://chebe163.caltech.edu/2018w/handouts/intro_to_latex.html). You could also find various $\\LaTeX$ tutorials and cheat sheets online.\n",
    "\n",
    "#### Include Images\n",
    "If you are still getting familiar with using LaTeX, handwrite the response on paper or the stylus. Take a picture or screenshot of your answer, and include that image in the Jupyter Notebook. Be sure to include that image in the `\\imgs` directory. Let's say you have your Q1 response saved as `imgs/Q1.png`; the markdown syntax to include that image is `![Q1](imgs/Q1.png)`. \n",
    "\n",
    "## Important Notice\n",
    "\n",
    "You must check both submission output on the gradescope (`Assignment 8` and `Assignment 8 - Manual Grading`) correctly reflects your work and responses. If you notice inconsistencies between your notebook and the Manual Grading portion, you need to make a campuswire post, and we can help you with that.\n",
    "\n",
    "**Other**\n",
    "\n",
    "If you are not feeling comfortable with the programming assignments in this homework, it might help to take a look at [https://github.com/UCSD-COGS108/Tutorials](https://github.com/UCSD-COGS108/Tutorials)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf4e0a1",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb741e7",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Neural networks are  function approximators (https://en.wikipedia.org/wiki/Universal_approximation_theorem) that are capable of learning rich mappings of inputs $x$ to targets $y$, often without explicit feature engineering. For an arbitrary function $f$, a neural network can be defined as $f(\\mathbf{x};\\mathbf{w})$ with inputs $\\mathbf{x}$ and parameters $\\mathbf{w}$. The set of parameters $\\mathbf{w}$ can be optimized in a neural network through a special implementation of gradient descent: backpropagation.\n",
    "\n",
    "Backpropagation is **the recursive application of the chain rule**.  For a single perceptron (or any other algorithm) we know how to do gradient descent to change parameters so as to minimize errors.  But in a multi-layer neural network that corresponds to the last layer of the network... that's where we know the error and that's where we can optimize the final set of weights to minimize the loss. But what about the other layers, how do we modify them to help minimize loss at the output stage? By taking the loss gradient calculated for the output layer and propagating that gradient backwards through the chain rule to the layer before. That is, we apportion \"responsibility\" for the errors at the output layer among the weights in the layer before that. \n",
    "\n",
    "Before we can run backpropagation, we must first run a forward pass with our data, inputting $\\mathbf{x}$ to our network, calculating the prediction $f(\\mathbf{x};\\mathbf{w})$, comparing that prediction to the desired output $y$ in the form of some loss function. After the forward pass, we can calculate the loss gradients for each step from back to front through the chain rule at each stage. \n",
    "\n",
    "The gradient of a variable $f$ w.r.t a variable $q$ can be described as the responsibility a small change in $q$ has for causing change in $f$. What about when there's a variable in between $q$ and $f$? What if $f$ is a function of  $r$ which is a function of $q$? The chain rule says that to calculate the gradient $\\frac{\\partial f}{\\partial q}$,  we must multiply the impact of $q$ on $r$ and the impact of $r$ on $f$. This is the recursive application of the chain rule, with the formula:\n",
    "\n",
    "$$ \\frac{\\partial f}{\\partial q} = \\frac{\\partial f}{\\partial r}  \\frac{\\partial r}{\\partial q} $$\n",
    "\n",
    "The $\\partial r$ terms cancel out if we multiply these gradients together! This flow of the gradients, where we calculate the impact of an earlier variable on a later variable by going back to front, is the mathematical mechanism behind how neural networks learn.\n",
    "\n",
    "\n",
    "Instead of making you calculate backpropagation on a complicated neural network, we will be using a simple scaled linear function $f(x,w,z,b) = z(wx+b)$. But this method works for any network! You will compute all gradients and the missing values in the computational graph below given $x=2$, $w=5$, $b=-2$, $ z=3$. On the forward pass solve for the intermediary variables $q$ and $r$, as well as $f$ and their gradients. Filling in the values in the graph may help you construct the answer.  But you will not be graded on filling the graph, you must put your answers in the questions below for points. Show your work using the formula for the chain rule.\n",
    "\n",
    "\n",
    "\n",
    "![comp-graph](imgs/computational-graph.png)\n",
    "\n",
    "\n",
    "Calculate the numerical values of $q$, $r$, and $f$. \n",
    "\n",
    "$q = $\n",
    "\n",
    "$r =$\n",
    "\n",
    "$f = $\n",
    "\n",
    "\n",
    "_Points:_ 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601c2963",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c12298",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Intermediary Variables\n",
    "Write $q$, $r$, and $f$ in terms of the two variables that are used to compute them. This will help you calculate their gradients.\n",
    "\n",
    "Hint: For example, you would write $r$ in terms of $q$ and $b$.\n",
    "\n",
    "_Points:_ 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903ce472",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f3cee4",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Intermediary Gradients\n",
    "\n",
    "Use the intermediary equations you found above to compute the gradients. Show your work.\n",
    "\n",
    "$\\frac{\\partial r}{\\partial b}$,\n",
    "$\\frac{\\partial r}{\\partial q}$,\n",
    "$\\frac{\\partial q}{\\partial w}$,\n",
    "$\\frac{\\partial q}{\\partial x}$\n",
    "\n",
    "_Points:_ 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11612e0b",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a621189",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Final Local Gradients\n",
    "Use the intermediary gradients calculated above to calculate the final gradients of the function $f$ w.r.t. each variable. Show your work.\n",
    "\n",
    "$\\frac{\\partial f}{\\partial f}$,\n",
    "$\\frac{\\partial f}{\\partial z}$,\n",
    "$\\frac{\\partial f}{\\partial r}$,\n",
    "$\\frac{\\partial f}{\\partial q}$,\n",
    "$\\frac{\\partial f}{\\partial b}$,\n",
    "$\\frac{\\partial f}{\\partial x}$,\n",
    "$\\frac{\\partial f}{\\partial w}$\n",
    " \n",
    "\n",
    "_Points:_ 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1867df",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91390b81",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Gradient Descent Update Rule\n",
    "\n",
    "Typically we update the weights of a neural network with the gradient of the loss function w.r.t. the weights $\\frac{\\partial L}{\\partial w}$. In this toy problem, since we have no loss, we will just use the gradient wr.t. the output $f$. If we use the following gradient descent update rule for $w$ and $b$, what would the new values be? The $\\alpha$ is $0.01$ in this case. Show your work.\n",
    "\n",
    "\n",
    "$$w_t = w_{t-1} - \\alpha(\\frac{\\partial f}{\\partial w})$$\n",
    "$$b_t = b_{t-1} - \\alpha(\\frac{\\partial f}{\\partial b})$$\n",
    "\n",
    "_Points:_ 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b490195a",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed0a719",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# Digit Classification with a Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3e6cd3",
   "metadata": {},
   "source": [
    "In this coding portion, most of the code is provided for you. You will need to fill in missing code, but most of it is given. We will focus on creating a simple feed-forward classification neural network to classify handwritten digits between 0-9 from the MNIST dataset into their respective classes.\n",
    "A feed-forward neural network is a classification algorithm that consists of a large number of perceptrons, organized in layers & each unit in the layer is connected with all the units or neurons present in the previous layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a563edb8",
   "metadata": {},
   "source": [
    "Before, we get started we need to install Pytorch.\n",
    "About Pytorch - https://pytorch.org/\n",
    "Pytorch is an open-source machine learning and deep learning framework widely used in applications such as natural language processing, image classification and computer vision applications. It was developed by Facebook’s AI Research and later adapted by several conglomerates such as Uber, Twitter, Salesforce, and NVIDIA.\n",
    "PyTorch comes with several specially developed modules like torchtext, torchvision and other classes such as torch.nn, torch.optim, Dataset, and Dataloader to help you create and train neural networks to work with a different machine and deep learning areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65771d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==1.12.0\n",
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f411d84a",
   "metadata": {},
   "source": [
    "Note: Please restart your kernel after pip installing the above packages. Click kernel > Restart.\n",
    "Then run the following import cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997c488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466886c2",
   "metadata": {},
   "source": [
    "About the Dataset\n",
    "\n",
    "Torchvision provides many built-in datasets in the torchvision.datasets module, as well as utility classes for building your own datasets. - https://pytorch.org/vision/stable/datasets.html\n",
    "We'll be using one of these built-in datasets for our classification task.\n",
    "The MNIST dataset, also known as the Modified National Institute of Standards and Technology dataset, consists of 60,000 small square 28×28 grayscale images of handwritten digits between 0 to 9 divided into ten different classes. This dataset is mainly used for text classification using deep learning models.\n",
    "The MNIST database contains 60,000 training images and 10,000 testing images.\n",
    "Load the MNIST dataset from Pytorch\n",
    "\n",
    "The following cell transforms the dataset into a Pytorch friendly format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c31ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "# Read in train_data and test_data from built-in MNIST dataset, \n",
    "# transform into Pytorch tensor format\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f01cd1c",
   "metadata": {},
   "source": [
    "Since the entire dataset is around 70k images - which will take a TON of time to train on a CPU, we will take the first 10% of images for our train and test set. Don't worry if you don't fully understand the details - just run the code provided! If you are courious about the purpose and the function of each line, feel free to post a Piazza post. PyTorch's dataloader takes a dataset object as input, which is responsible for loading and returning individual data samples. The dataloader then takes care of batching, shuffling, and multiprocessing the data samples, making it efficient to feed them into a deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a06d7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the entire dataset is around 60k images \n",
    "# - which will take a TON of time to train on a CPU\n",
    "# We subset the entire set - and pick the first 10% for train and test. \n",
    "train_dataset = Subset(train_data, indices=range(len(train_data) // 10))\n",
    "test_dataset = Subset(train_data, indices=range(len(test_data) // 10))\n",
    "\n",
    "# Just run this cell to use Pytorch dataloader to load train and test sets \n",
    "# Note that we specify batch size = 100. \n",
    "# This means that we will have 60 batches in total \n",
    "# - and each batch contains 100 images for the train set \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=100, \n",
    "                                           shuffle=True)\n",
    "\n",
    "# Note that we specify batch size = 100. \n",
    "# This means that we will have 10 batches in total \n",
    "# - and each batch contains 100 images for the test set \n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False)\n",
    "# A quick check to ensure our train_loader loaded our 6000 train images properly \n",
    "print('For the train set:')\n",
    "print('Total number of batches:', len(train_loader))\n",
    "print('Number of images in each batch in train set:', train_loader.batch_size)\n",
    "print('Total number of images in train set:', len(train_loader.dataset))\n",
    "print()\n",
    "\n",
    "\n",
    "# A quick check to ensure our test_loader loaded our 1000 test images properly \n",
    "print('For the test set:')\n",
    "print('Total number of batches:', len(test_loader))\n",
    "print('Number of images in each batch in test set:', test_loader.batch_size)\n",
    "print('Total number of images in test set:', len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb62076",
   "metadata": {},
   "source": [
    "Great! Now that we have successfully loaded our train and test sets, let's take a quick look at what our test set images look like.\n",
    "Please run the following code cell to take a look at the 10 random images in our test set.\n",
    "The ground truth labels are displayed in blue as the title of the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5189c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = iter(test_loader)\n",
    "example_data, example_targets = next(examples)\n",
    "\n",
    "\n",
    "params = {\"text.color\" : \"blue\",\n",
    "          \"xtick.color\" : \"black\",\n",
    "          \"ytick.color\" : \"black\"}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "indices = np.random.randint(0, len(test_loader), size=10)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 5, figsize=(10, 5))\n",
    "axs = axs.flatten()\n",
    "examples = iter(test_loader)\n",
    "\n",
    "for i, index in enumerate(indices):\n",
    "    # Get the image and ground truth label\n",
    "\n",
    "    example_data, example_targets = next(examples)\n",
    "    image, label = example_data[index][0], example_targets[index].item()\n",
    "\n",
    "    # Plot the image with its ground truth\n",
    "    axs[i].imshow(image.reshape(28, 28), cmap='gray')\n",
    "    axs[i].set_title(f'GT: {label}')\n",
    "    axs[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d1b5a8",
   "metadata": {},
   "source": [
    "## Creating A Neural Network with 1 Hidden Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7d53a6",
   "metadata": {},
   "source": [
    "Now, let's focus on building our fully connected neural network that will classify these test images into one of 10 different classes, i.e the digits (0-9).\n",
    "\n",
    "We will first define our hyperparameters for our neural network.\n",
    "Given the hand written digit as the input to our model, what should be the input size of our Fully Connected Network?\n",
    "\n",
    "_Points:_ 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e692504a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "examples = iter(test_loader)\n",
    "example_data, example_targets = next(examples)\n",
    "image, label = example_data[index][0], example_targets[index].item()\n",
    "\n",
    "# Take a look at our input: image\n",
    "print(image.shape)\n",
    "\n",
    "# Based on that input, what should be our network's input size?\n",
    "input_size = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8fe347",
   "metadata": {},
   "source": [
    "## Linear Layers\n",
    "The code cell below defines a fully connected neural network with a single hidden layer. Your job is to fill in the lines for the first and second linear layer.\n",
    "You can accomplish this using the nn.Linear function and setting the appropriate input and output sizes for each layer - https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "Hint: Use the hyperparameters we define below!\n",
    "\n",
    "_Points:_ 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e19df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our hidden layer will have input size 500. \n",
    "hidden_size = 500 \n",
    "\n",
    "# num_classes = 10, since we want to classify digits into one of 10 classes \n",
    "num_classes = 10\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c6cf42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "\n",
    "# The neural network is defined as a class called NeuralNet, which inherits from the nn.Module class in PyTorch. \n",
    "# This allows the network to take advantage of the built-in functionality of PyTorch for training and optimization.\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    # initializes the neural network and sets its parameters. \n",
    "    # It takes three arguments - input_size, hidden_size, and num_classes \n",
    "    # input_size - the size of the input layer, \n",
    "    # hidden_size - the number of neurons in the hidden layer, \n",
    "    # num_classes - the number of output classes\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "\n",
    "        # Your task: Create the first hidden layer using nn.Linear \n",
    "        # Hint: Think about the input size of the first layer. \n",
    "        # Since the hidden layer is next, what should the output size of this first linear layer be?\n",
    "        self.l1 = ...\n",
    "        \n",
    "        \n",
    "        # a Rectified Linear Unit (ReLU) activation function applied to first layer \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Your task: Create the second linear layer using nn.Linear \n",
    "        # Hint: Think about the input size of the second layer (This layer is connected to the hidden layer!)\n",
    "        # This layer produces the final output of the network so what should the output size be?\n",
    "        self.l2 = ...\n",
    " \n",
    "\n",
    "    # defines how the input data is processed through the neural network. \n",
    "    # connect each layer together as following:  l1 -> relu -> l2\n",
    "    def forward(self, x):\n",
    "        x = ...\n",
    "        x = ...\n",
    "        out = ...\n",
    "        return out\n",
    "    \n",
    "\n",
    "# Create an instance of NeuralNet and store it in model\n",
    "model = NeuralNet(input_size, hidden_size, num_classes)\n",
    "model # View a brief summary of your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca4fba1",
   "metadata": {},
   "source": [
    "## Training the network\n",
    "Initially, the weights are randomly initialized so our accuracy would be quite poor. We need to update these random weight values using a training loop and a Cross Entropy loss. In the following code cells, we will set up the training loop for the network.\n",
    "Your task will be to fill in the loss function within the loop which is used to calculate the error between the predicted output and the actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a61ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify loss function\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Specify optimization algorithm to be used \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "n_total_batches = len(train_loader)\n",
    "print('Total Batches in train set:', n_total_batches)\n",
    "losses = []\n",
    "\n",
    "# Outer loop - runs over number of epochs \n",
    "for epoch in range(num_epochs):\n",
    "    # Loop over each image and label \n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        \n",
    "        # origin shape: [100, 1, 28, 28]\n",
    "        # resized: [100, 784] to be able to pass into network\n",
    "        images = images.reshape(-1, 28*28)\n",
    "\n",
    "        # Your task: Fill in the forward pass\n",
    "        # Forward pass - pass input image through network \n",
    "        outputs = ...\n",
    "        \n",
    "        # Your task: Fill in the loss function \n",
    "        # that calculates the error between the predicted output and the actual labels\n",
    "        # Hint: We already defined this above. Think about what arguments a loss function should take. \n",
    "        loss = ...\n",
    " \n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{n_total_batches}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b411516",
   "metadata": {},
   "source": [
    "Let's compare the accuracy of our network on the test images now after training.\n",
    "We expect the network to have improved accuracy (since all the weights have been updated during the training process and we expect the network to have learned to recognize visual features to distinguish between input images.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c4cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 1000 test images: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc955ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot random 10 images from MNIST test set with ground truth and predicted label \n",
    "\n",
    "import numpy as np\n",
    "indices = np.random.randint(0, len(test_loader), size=10)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 5, figsize=(10, 5))\n",
    "axs = axs.flatten()\n",
    "examples = iter(test_loader)\n",
    "\n",
    "for i, index in enumerate(indices):\n",
    "    # Get the image and ground truth label\n",
    "\n",
    "    example_data, example_targets = next(examples)\n",
    "    image, label = example_data[index][0], example_targets[index].item()\n",
    "\n",
    "    # Make a prediction with the model\n",
    "    with torch.no_grad():\n",
    "        image = image.reshape(-1, 28*28)\n",
    "\n",
    "        prediction = model(image)\n",
    "        predicted_label = torch.argmax(prediction, dim=1).item()\n",
    "\n",
    "    # Plot the image with its ground truth and predicted labels\n",
    "    axs[i].imshow(image.reshape(28, 28), cmap='gray')\n",
    "    axs[i].set_title(f'GT: {label}, Pred: {predicted_label}')\n",
    "    axs[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b004f42",
   "metadata": {},
   "source": [
    "We can see that the predictions now match our ground truth for most images.\n",
    "It's important to note that the performance of the network can depend on several factors, such as the network architecture, hyperparameters, and the size and complexity of the dataset. Additionally as with other supervised ML algorithms, the network may not be able to generalize well to new, unseen data if it was overfitted on the training data.\n",
    "Congratulations! You have successfully trained your first neural network and used it to classify 10000 images from MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8244314",
   "metadata": {},
   "source": [
    "# End of A8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325e5edf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit.\n",
    "\n",
    "Please make sure to see the output of the gradescope autograder. You are responsible for waiting and ensuring that the autograder is executing normally for your submission. Please create a campuswire post if you see errors in autograder execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a28088a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.export(pdf=False, force_save=True, run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0de70",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "digits-1": {
     "name": "digits-1",
     "points": 0.5,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "digits-2": {
     "name": "digits-2",
     "points": 0.5,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "digits-3": {
     "name": "digits-3",
     "points": 0.5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert acc > 0.89\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
