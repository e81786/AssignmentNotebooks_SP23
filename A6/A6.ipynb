{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3d44b8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"A6.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed10fa02",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-68f2f0ed9883b594",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 6\n",
    "\n",
    "\n",
    "## **Due: May 17th (Wednesday), 2023, 11:59pm (PT)**\n",
    "\n",
    "### **Instructions:**\n",
    "\n",
    "Your Jupyter notebook assignment will often have 3 elements: written answers, code answers, and quiz answers. For written answers, you may insert images of your handwritten work in code cells, or write your answers in markdown and LaTeX. For quiz answers, your `record.txt` file will record your answer choices in the quiz modules for submission. Both your quiz answers and code answers will be autograded on Gradescope. This assignment does not have the quiz portion.\n",
    "\n",
    "For all elements, DO NOT MODIFY THE CELLS. Put your answers **only** in the answer cells given, and **do not delete cells**. If you fail to follow these instructions, you will lose points on your submission.\n",
    "\n",
    "Make sure to show the steps of your solution for every question to receive credit, not just the final answer. You may search information online but you will need to write code/find solutions to answer the questions yourself. You will submit your .ipynb file and record.txt to gradescope when you are finished.\n",
    "\n",
    "### **Late Policy:**\n",
    "\n",
    "Late assignments will be accepted at 75% credit up to one week late. Consult the syllabus for more info on the late policy.\n",
    "\n",
    "### How to Include Your Math Written Answer?\n",
    "\n",
    "You could use inline $\\LaTeX$ in markdown (recommended) or use markdowns' include image functionality to submit your written responses.\n",
    "\n",
    "#### $\\LaTeX$ (recommended)\n",
    "[Here is a fantastic tutorial from CalTech about using $\\LaTeX$ in Jupyter Notebook.](http://chebe163.caltech.edu/2018w/handouts/intro_to_latex.html). You could also find various $\\LaTeX$ tutorials and cheat sheets online.\n",
    "\n",
    "#### Include Images\n",
    "If you are still getting familiar with using LaTeX, handwrite the response on paper or the stylus. Take a picture or screenshot of your answer, and include that image in the Jupyter Notebook. Be sure to include that image in the `\\imgs` directory. Let's say you have your Q1 response saved as `imgs/Q1.png`; the markdown syntax to include that image is `![Q1](imgs/Q1.png)`. \n",
    "\n",
    "## Important Notice\n",
    "\n",
    "You must check both submission output on the gradescope (`Assignment 6` and `Assignment 6 - Manual Grading`) correctly reflects your work and responses. If you notice inconsistencies between your notebook and the Manual Grading portion, you need to make a campuswire post, and we can help you with that.\n",
    "\n",
    "**Other**\n",
    "\n",
    "If you are not feeling comfortable with the programming assignments in this homework, it might help to take a look at [https://github.com/UCSD-COGS108/Tutorials](https://github.com/UCSD-COGS108/Tutorials)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5435fa91",
   "metadata": {},
   "source": [
    "# Question 1: Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e74369",
   "metadata": {},
   "source": [
    "Cross-validation is implemented in `sklearn`. In this question, you will use `GridSearchCV` from the `model_selection` package to find optimal hyperparameters settings for logistic regression classifiers. Implement the function `cross_validation_logistic_regression` and test it on the breast cancer data. \n",
    "\n",
    "_Points:_ 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49187273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def cross_validation_logistic_regression(X_data, Y_data, k_fold, hyperparams):\n",
    "    \"\"\" test the hyperparams for a logistic regression classifier \n",
    "    \n",
    "    Args:\n",
    "        X_data (np.ndarray): X data (N x m, where m is the number of features)\n",
    "        Y_data (np.ndarray): Y data (N x 1) \n",
    "        k_fold (int): k for k-fold cross validation\n",
    "        hyperparams (dict): a dictionary of hyperparameters to test, mapping \n",
    "            the name of a hyper-parameters to the list of values to test\n",
    "    \n",
    "    Returns:\n",
    "        best_params (dict): the paramters that gives best performance on the hold-out data\n",
    "        mean_train_score (np.ndarray): mean of test score\n",
    "        std_train_score (np.ndarray): standard deviation of test score\n",
    "        HINTS: they can be read from the attribute `cv_results_` of a `GroundSearchCV` agent. \n",
    "    \"\"\"\n",
    "    # initialize a logistic regression classifier\n",
    "    log_reg = ...\n",
    "    \n",
    "    # use GridSearchCV to do cross validation\n",
    "    # for 'scoring' (metrics to measure performance) use accuracy\n",
    "    \n",
    "    # get the paramters that gives best performance on the hold-out data\n",
    "    best_params = ...\n",
    "    \n",
    "    # get the mean and standard deviation of test score\n",
    "    mean_train_score = ...\n",
    "    std_train_score = ...\n",
    "    \n",
    "    return best_params, mean_train_score, std_train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcef103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# data\n",
    "cancer_data = load_breast_cancer()\n",
    "cancer_data_X = cancer_data.data[:200]\n",
    "cancer_data_Y = cancer_data.target[:200]\n",
    "\n",
    "# paremeters to tune\n",
    "params = {\n",
    "    'C':[0.01, 0.5, 10],\n",
    "    'solver': ['lbfgs', 'newton-cholesky'],\n",
    "}\n",
    "\n",
    "# 5 fold cross-validation\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "    best_params, mean_scores, std_scores = cross_validation_logistic_regression(\n",
    "        X_data=cancer_data_X,\n",
    "        Y_data=cancer_data_Y, \n",
    "        k_fold=5, \n",
    "        hyperparams=params)\n",
    "\n",
    "print(f'The optimal parameters settings: {best_params}')\n",
    "print(f'accuracies: {np.round(mean_scores, decimals=3)}')\n",
    "print(f'(with std: {np.round(std_scores, decimals=3)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f719f943",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"cross_validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c07546",
   "metadata": {},
   "source": [
    "# Question 2: SVM\n",
    "\n",
    "Consider a dataset ${(xi, yi), i = 1, 2, ..., 10}$ where $x = (x_1, x_2)$ and $y \\in {−1, +1}$, as shown in the figure below. Suppose we have trained a support vector machine (SVM) classifier on the dataset, which has the decision boundary $l :w^Tx + b = 0$. The SVM classifier is optimized as following:\n",
    "\n",
    "\\begin{align*}\n",
    "Find &: \\arg\\min_w = \\frac{1}{2} ||w||_2^2 \\\\\n",
    "\\text{Subject to} &, \\forall i : w^Tx_i + b \\geq +1, \\text{if } y_i = +1, \\\\\n",
    "& w^Tx_i + b \\leq -1, \\text{if } y_i = −1.\n",
    "\\end{align*}\n",
    "\n",
    "We define $l^+: w^Tx_i + b = +1$ as the positive plane and $l^-: w^Tx_i + b = -1$ as the negative plane. After training the SVM classifier using the gradient descent method for several iterations to reach an intermediate state, we have obtained the positive plane and the negative plane, which are indicated as solid lines in the Figure below.\n",
    "\n",
    "**Hint**:\n",
    "\n",
    "$X_1=(4.0, 0.5), X_2(2.0, 2.0)$ are on the negative plane\n",
    "\n",
    "$X_3=(2.0, 3.0)$ is on the positive plane"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6692f4c",
   "metadata": {},
   "source": [
    "![arg_max](imgs/svm_q2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae45de1f",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "2.1 Calculate the w and b from the positive plane and negative plane.\n",
    "\n",
    "_Points:_ 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841c1283",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1303b720",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "2.2 Calculate the size of the margin.\n",
    "\n",
    "_Points:_ 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ea2f18",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05b6a53",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "# Question 3: SVM gradient\n",
    "\n",
    "Given a training dataset $S_{\\text{training}} = \\{(x_i, y_i), i = 1, . . . , n\\}$, we wish to optimize the loss $L(w, b)$ of a linear SVM classifier:\n",
    "\n",
    "$$L(w, b) = \\frac{1}{2}||w||_2^2 + C\\sum_{i=1}^{n} 1 − y_i(w^T x_i + b)_{+} $$\n",
    "\n",
    "\n",
    "where $(z)_+ = max(0, z)$ is called the rectifier function and C is a scalar constant.\n",
    "\n",
    "The optimal weight vector $w^∗$ and the bias $b^*$ used to build the SVM classifier are defined as follows:\n",
    "\n",
    "$$ w^∗, b^∗ = \\arg \\min_{w,b} = L(w, b)$$\n",
    "\n",
    "In this problem, we attempt to obtain the optimal parameters $w∗$ and $b∗$ by using a standard gradient descent algorithm.\n",
    "\n",
    "**[Hint]**: To find the derivative of $L(w, b)$, please consider two cases:\n",
    "\n",
    "(a) $1 − y_i(w^T x_i + b) \\geq 0$\n",
    "\n",
    "(b) $1 − y_i(w^T x_i + b) < 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434be230",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 3.1\n",
    "\n",
    "find the derivative $\\frac{\\partial L(w, b)}{\\partial w}$\n",
    "\n",
    "_Points:_ 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15334fbf",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238e9dba",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 3.2\n",
    "\n",
    "find the derivative $\\frac{\\partial L(w, b)}{\\partial b}$\n",
    "\n",
    "_Points:_ 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc94043",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df6ea3c",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "# Question 4: SVM margin\n",
    "\n",
    "As shown in the Figure below, given $w$ and $b$ we have the decision boundary (marked as a black line) defined as follows:\n",
    "\n",
    "$$w^T x + b = 0$$\n",
    "\n",
    "In parallel to the decision boundary, we have the positive plane (marked as a red line) as\n",
    "\n",
    "$$w^T x + b = +1$$\n",
    "\n",
    "and the negative plane (marked as a blue line) defined as:\n",
    "\n",
    "$$w^T x + b = -1$$\n",
    "\n",
    "We pick an arbitrary point x on the negative plane, and draw a purple line that (i) passes x and (ii) is perpendicular to the negative plane. The intersection between this purple line and the positive plane can be denoted as $x^+$. Thus, \n",
    "\n",
    "we have the following equation that describes the relationship between $x^+$ and $x^-$:\n",
    "\n",
    "$$x^+ = x^- +\\lambda w$$\n",
    "\n",
    "where $\\lambda \\in R$ is an undetermined scalar. The margin $M$ is defined as the distance\n",
    "between the positive and the negative planes, as:\n",
    "\n",
    "$$M = ||X^+ - X^-||_2 = \\sqrt{<\\lambda w, \\lambda w>}$$\n",
    "\n",
    "Please derive the following:\n",
    "\n",
    "$$M = \\frac{2}{\\sqrt{<w, w>}}$$\n",
    "\n",
    "![arg_max](imgs/svm_margin.png)\n",
    "\n",
    "**[Hint]**: First try to represent $\\lambda$ in the form of $w$.\n",
    "\n",
    "_Points:_ 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d932d4",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ab656b",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# Q5: SVM concept questions\n",
    "\n",
    "For multiple choice questions, write your solution as a list of strings by replacing the \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1a9a6f",
   "metadata": {},
   "source": [
    "Which one below best describes what support vectors are:\n",
    "\n",
    "A. The training samples that determine the positive and the negative planes.\n",
    "\n",
    "B. The decision boundary.\n",
    "\n",
    "C. The test samples that determine the positive and the negative planes.\n",
    "\n",
    "D. The positive and the negative planes.\n",
    "\n",
    "_Points:_ 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d2b8fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MCQ_1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6f322e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"svm_concepts_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de01e5f",
   "metadata": {},
   "source": [
    "Consider a dataset $S = \\{(x_i y_i), i = 1, 2, ..., n\\}$ where $x = [x_1, x_2]^T$ and $y \\in \\{−1, +1\\}$. Here we try to learn a linear SVM classifier parameterized by weight vector $w$ and bias $b$ to fit the dataset $S$. Which one is the appropriate loss function for the linear SVM classifier from the options below:\n",
    "\n",
    "A. $L(w, b) = \\frac{1}{2}w^Tw - C \\times \\sum_{i=1}^{n} \\max(0, 1 − y_i \\times (w^Tx_i + b))$\n",
    "\n",
    "B. $L(w, b) = \\frac{2}{\\sqrt{w^Tw}} - C \\times \\sum_{i=1}^{n} \\max(0, 1 − y_i \\times (w^Tx_i + b))$\n",
    "\n",
    "C. $L(w, b) = \\frac{1}{2}w^Tw + C \\times \\sum_{i=1}^{n} \\max(0, 1 − y_i \\times (w^Tx_i + b))$\n",
    "\n",
    "D. $L(w, b) = \\frac{2}{\\sqrt{w^Tw}} + C \\times \\sum_{i=1}^{n} \\max(0, 1 − y_i \\times (w^Tx_i + b))$\n",
    "\n",
    "_Points:_ 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9a286a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MCQ_2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4124af7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"svm_concepts_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279cb289",
   "metadata": {},
   "source": [
    "In the following figure, We use a black line to mark the decision boundary of a linear SVM classifier parameterized by weight vector w and bias b. If we start to increase the margin of the classifier, what would happen to w?\n",
    "\n",
    "![svm_margin](imgs/svm_margin.png)\n",
    "\n",
    "A. w will have smaller magnitude.\n",
    "\n",
    "B. w will have greater magnitude.\n",
    "\n",
    "C. The magnitude of w does not change.\n",
    "\n",
    "D. None of above.\n",
    "\n",
    "_Points:_ 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f82643",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MCQ_3 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1f5714",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"svm_concepts_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e7f2ca",
   "metadata": {},
   "source": [
    "# End of A6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dcb328",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit.\n",
    "\n",
    "Please make sure to see the output of the gradescope autograder. You are responsible for waiting and ensuring that the autograder is executing normally for your submission. Please create a campuswire post if you see errors in autograder execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e30ea0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.export(pdf=False, force_save=True, run_tests=True, files=['imgs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef0b9a6",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "cross_validation": {
     "name": "cross_validation",
     "points": 0.5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # sanity check\n>>> assert isinstance(best_params, dict), \"best_params should be a dictionary of hyper-parameters\"\n>>> assert 'C' in best_params, \"C missing from the hyperparameters dict\"\n>>> assert 'solver' in best_params, \"solver missing from the hyperparameters dict\"\n>>> assert isinstance(mean_scores, np.ndarray) and mean_scores.shape == (6,), \"mean_scores should be an np array of length 6\"\n>>> assert isinstance(std_scores, np.ndarray) and std_scores.shape == (6,), \"std_scores should be an np array of length 6\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "svm_concepts_1": {
     "name": "svm_concepts_1",
     "points": 0.3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # sanity check\n>>> all_options = [\"A\", \"B\", \"C\", \"D\"]\n>>> check_valid = lambda ans, all_options: all([chosen in all_options for chosen in ans])\n>>> assert check_valid(MCQ_1, all_options), \"Is your answer within the option of A/B/C/D?\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "svm_concepts_2": {
     "name": "svm_concepts_2",
     "points": 0.3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # sanity check\n>>> all_options = [\"A\", \"B\", \"C\", \"D\"]\n>>> check_valid = lambda ans, all_options: all([chosen in all_options for chosen in ans])\n>>> assert check_valid(MCQ_2, all_options), \"Is your answer within the option of A/B/C/D?\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "svm_concepts_3": {
     "name": "svm_concepts_3",
     "points": 0.3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # sanity check\n>>> all_options = [\"A\", \"B\", \"C\", \"D\"]\n>>> check_valid = lambda ans, all_options: all([chosen in all_options for chosen in ans])\n>>> assert check_valid(MCQ_3, all_options), \"Is your answer within the option of A/B/C/D?\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
