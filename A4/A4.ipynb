{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075bb7a1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"A4.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b26ffa9",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-68f2f0ed9883b594",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 4\n",
    "\n",
    "\n",
    "## **Due: May 3rd (Wednesday), 2023, 8:00pm (PT)**\n",
    "\n",
    "### **Instructions:**\n",
    "\n",
    "Your Jupyter notebook assignment will often have 3 elements: written answers, code answers, and quiz answers. For written answers, you may insert images of your handwritten work in code cells, or write your answers in markdown and LaTeX. For quiz answers, your `record.txt` file will record your answer choices in the quiz modules for submission. Both your quiz answers and code answers will be autograded on Gradescope. This assignment does not have the quiz portion.\n",
    "\n",
    "For all elements, DO NOT MODIFY THE CELLS. Put your answers **only** in the answer cells given, and **do not delete cells**. If you fail to follow these instructions, you will lose points on your submission.\n",
    "\n",
    "Make sure to show the steps of your solution for every question to receive credit, not just the final answer. You may search information online but you will need to write code/find solutions to answer the questions yourself. You will submit your .ipynb file and record.txt to gradescope when you are finished.\n",
    "\n",
    "### **Late Policy:**\n",
    "\n",
    "Late assignments will be accepted at 75% credit up to one week late. Consult the syllabus for more info on the late policy.\n",
    "\n",
    "### How to Include Your Math Written Answer?\n",
    "\n",
    "You could use inline $\\LaTeX$ in markdown (recommended) or use markdowns' include image functionality to submit your written responses.\n",
    "\n",
    "#### $\\LaTeX$ (recommended)\n",
    "[Here is a fantastic tutorial from CalTech about using $\\LaTeX$ in Jupyter Notebook.](http://chebe163.caltech.edu/2018w/handouts/intro_to_latex.html). You could also find various $\\LaTeX$ tutorials and cheat sheets online.\n",
    "\n",
    "#### Include Images\n",
    "If you are still getting familiar with using LaTeX, handwrite the response on paper or the stylus. Take a picture or screenshot of your answer, and include that image in the Jupyter Notebook. Be sure to include that image in the `\\imgs` directory. Let's say you have your Q1 response saved as `imgs/Q1.png`; the markdown syntax to include that image is `![Q1](imgs/Q1.png)`. \n",
    "\n",
    "## Important Notice\n",
    "\n",
    "You must check both submission output on the gradescope (`Assignment 4` and `Assignment 4 - Manual Grading`) correctly reflects your work and responses. If you notice inconsistencies between your notebook and the Manual Grading portion, you need to make a campuswire post, and we can help you with that.\n",
    "\n",
    "**Other**\n",
    "\n",
    "If you are not feeling comfortable with the programming assignments in this homework, it might help to take a look at [https://github.com/UCSD-COGS108/Tutorials](https://github.com/UCSD-COGS108/Tutorials)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6546a35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Run me\n",
    "# !pip uninstall -y otter-grader\n",
    "# !pip install -q  git+https://github.com/scott-yj-yang/otter-grader.git --no-warn-script-location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c545e26",
   "metadata": {},
   "source": [
    "# Question 1: Cross Validation\n",
    "\n",
    "For multiple choice questions, write your solution as a list of strings by replacing the \"...\" \n",
    "\n",
    "Ex.: `[\"A\", \"C\"]` if you think the answers are A and C) and `[\"A\"]` if you think the answer is A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10614607",
   "metadata": {},
   "source": [
    "K-fold cross validation allows us to test and compare many combinations of hyperparameters for a given model architecture or algorithm. When performing K-fold CV for model selection and assuming we chose a reasonable value of k, which model should we choose?\n",
    "\n",
    "A. The model that has the highest average training accuracy across all k-folds of cross validation.\n",
    "\n",
    "B. The model with the smallest differences between the average training accuracy and average test accuracy within a given fold.\n",
    "\n",
    "C. The model with the highest average test accuracy across folds.\n",
    "\n",
    "D. The model with the highest test accuracy in a given fold.\n",
    "\n",
    "_Points:_ 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4adff0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q1_1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb1a139",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"MCQ_1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfe2480",
   "metadata": {},
   "source": [
    "Why do we use nested cross validation? (Choose all that apply)\n",
    "\n",
    "A. To avoid over-fitting the model on the training set.\n",
    "\n",
    "B. To minimize the complexity of training on large data sets.\n",
    "\n",
    "C. In order to optimize the hyper-parameters of a model.\n",
    "\n",
    "D. To take advantage of small test sets in validating accuracy.\n",
    "\n",
    "_Points:_ 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0647b72d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q1_2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2880e8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"MCQ_1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84024d27",
   "metadata": {},
   "source": [
    "What is a drawback with using nested cross validation?\n",
    "\n",
    "A. It can lead to over-fitting of the model.\n",
    "\n",
    "B. It has a very expensive computation relative to other methods.\n",
    "\n",
    "C. It can lead to over-fitting of the hyper-parameters.\n",
    "\n",
    "D. There are no drawbacks to using nested cross validation.\n",
    "\n",
    "_Points:_ 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2583de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q1_3 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b7d8ed",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"MCQ_1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f109af",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "If we have a small 1000 point dataset and we want to use k-fold cross validation, what are the advantages and disadvantages of using k=4 and k=1000 for model selection?\n",
    "\n",
    "_Points:_ 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ce9d47",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3837c7",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "# Question 2: Error Metrics\n",
    "\n",
    "Now consider that you want to develop a classification model to identify whether a tumor is a malignant tumor or a benign tumor. This model will assist doctors in deciding whether or not a patient needs chemotherapy. After generating predictions with your models (using the same test set), you generate two confusion matrices: A and B. Calculate the error metrics for both confusion matrices and use the metrics to justify which model is more appropriate for this task.\n",
    "\n",
    "Confusion Matrix A\n",
    "\n",
    "|              |          | predicted | diagnosis |       |\n",
    "|--------------|----------|-----------|-----------|-------|\n",
    "|              |          | postive   | negative  | total |\n",
    "| true classes | positive | 15        | 42        | 57    |\n",
    "| true classes | negative | 2         | 41        | 43    |\n",
    "|              | total    | 17        | 83        | 100   |\n",
    "\n",
    "Confusion Matrix B\n",
    "\n",
    "|              |          | predicted | diagnosis |       |\n",
    "|--------------|----------|-----------|-----------|-------|\n",
    "|              |          | postive   | negative  | total |\n",
    "| true classes | positive | 40        | 17        | 57    |\n",
    "| true classes | negative | 31        | 12        | 43    |\n",
    "|              | total    | 71        | 29        | 100   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea846004",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Question 2.1\n",
    "Compute the Recall for each confusion matrix and discuss its implications in this context:\n",
    "\n",
    "$$\\text{Recall} = \\frac{\\text{TP}}{\\text{TP + FN}}$$\n",
    "\n",
    "\n",
    "_Points:_ 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e1396f",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc363a7",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Question 2.2\n",
    "\n",
    "Compute the Precision for each confusion matrix and discuss its implications in this context:\n",
    "\n",
    "$$ \\text{Precision} = \\frac{\\text{TP}}{\\text{TP+FP}} $$\n",
    "\n",
    "_Points:_ 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea32d07",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af36e8d0",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Question 2.3\n",
    "\n",
    "Compute the F-value for each confusion matrix, what does this mean?:\n",
    "\n",
    "$$ \\text{F-value} = \\frac{\\text{2 * Precision * Recall}}{\\text{Precision + Recall}} $$\n",
    "\n",
    "_Points:_ 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09ff52a",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aba5bb3",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Question 2.4\n",
    "\n",
    "With the metrics you've gathered, which model is more appropriate for classifying cancer cells, the model that generated Confusion Matrix A or B? Why?\n",
    "\n",
    "_Points:_ 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361bbd66",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c3c64f",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# Question 3 Model Selection\n",
    "\n",
    "Read the following statements and identify whether they are true or false, Replace the \"...\" with your answer \n",
    "\n",
    "Ex.: `q3_5=True` if you think the answer to the fifth question is True. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bf8589",
   "metadata": {},
   "source": [
    "Nested K-Fold Cross Validation can be used for simultaneous model selection and validation.\n",
    "\n",
    "_Points:_ 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53fd997",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q3_1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e8096c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"TF_3_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bcd0f0",
   "metadata": {},
   "source": [
    "Using just point estimates of their mean validation performances, you can determine whether model $A$ is significantly better than model $B$\n",
    "\n",
    "_Points:_ 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9541d292",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q3_2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec4efd3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"TF_3_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc4e30d",
   "metadata": {},
   "source": [
    "Cross validation allows us to approximate a distribution over validation performance.\n",
    "\n",
    "_Points:_ 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69db3e30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q3_3 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90797c7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"TF_3_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8835cc82",
   "metadata": {},
   "source": [
    "It is impossible to over-fit a model using cross validation and grid-search.\n",
    "\n",
    "_Points:_ 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e65416",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q3_4 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa45124b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"TF_3_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50956a22",
   "metadata": {},
   "source": [
    "# Question 4 Decision Tree Modeling Decisions\n",
    "\n",
    "Consider the decision tree in the below figures. Suppose your colleague trained this model on a binary classification dataset of 'x's and 'o's but it isn't performing well in production. Because you took COGS 118A, they naturally turn to you for help. Your colleague tells you that in addition to performing poorly on real world data, they expected most 'x's to be cluster in the center of the feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02768462",
   "metadata": {},
   "source": [
    "![overfit_tree_decision_boundary](imgs/overfit_tree_decision_boundary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eccec7",
   "metadata": {},
   "source": [
    "![overfit_tree](imgs/overfit_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257f78ae",
   "metadata": {},
   "source": [
    "Based on your knowledge about decision tree modeling and regularization choices, how might you retain this model? (Select all that apply)\n",
    "\n",
    "A. Train with a maximum tree depth\n",
    "\n",
    "B. Train with a minimum tree depth\n",
    "\n",
    "C. Add an L1 regularization term\n",
    "\n",
    "D. Add a tree pruning technique\n",
    "\n",
    "E. Specify the minimum number of samples that can be split for any node\n",
    "\n",
    "F. Specify the maximum number of samples that can be split for any node\n",
    "\n",
    "G. Train with cost complexity: use a larger terminal node penalty\n",
    "\n",
    "H. Train with cost complexity: use a smaller terminal node penalty\n",
    "\n",
    "(Write your solution as a list of strings by replacing the \"...\" Ex.: `[\"A\", \"C\"]` if you think the answers are A and C.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99597ded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q4 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1644c017",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"MCQ_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eccdc09",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "# Question 5 Training and Test metrics\n",
    "\n",
    "Consider the following hyper-parameter search. Here $score$ (y-axis) is $R^2$ and $degree$ is some hyper-parameter. What parameter setting do you expect to generalize best to new data? Briefly explain your reasoning.\n",
    "\n",
    "![train_test_metrics](imgs/train_test_metrics.png)\n",
    "\n",
    "_Points:_ 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afbff5a",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f51316",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "# Question 6 K-Nearest Neighbors Classification\n",
    "\n",
    "Although k-Nearest Neighbors models are the \"dumbest\" machine learning classifiers, they can be highly accurate and valuable in the real world. With k-NN models, the model is the data itself; for a new data point you want to predict, you compute the similarity between that point and every point in your dataset. \n",
    "\n",
    "The predicted class for a test set example is the majority of k classes.\n",
    "\n",
    "![knn](imgs/knn.png)\n",
    "\n",
    "As you can imagine, with a large dataset, the model will perform exceptionally well. The downside is that the larger the dataset gets, the k-NN model will become more and more computationally complex: $O(1)$ training time (adding 1 data point to the model) and $O(n)$ testing time where $n$ equals the size of the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94e8b7e",
   "metadata": {},
   "source": [
    "### Euclidean Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec9bb4d",
   "metadata": {},
   "source": [
    "With this computational complexity in mind, we want to make our algorithm as efficient as possible. Write a `euc_distance` function that computes the euclidean distance between a point and all other points in our training data using numpy vectorization.\n",
    "\n",
    "_Points:_ 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80f38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0d7c30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def euc_distance(point, all_points):\n",
    "    \"\"\"\n",
    "    Input\n",
    "    -----\n",
    "    point: a numpy array of shape (1,2)\n",
    "    \n",
    "    all_points: a numpy array of shape (n,2)\n",
    "    \n",
    "    Returns\n",
    "    -----\n",
    "    distances: a numpy array of shape (n,)\n",
    "    \"\"\"\n",
    "    \n",
    "    distances = ...\n",
    "    \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bb1c90",
   "metadata": {},
   "source": [
    "### KNN Algorithm Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf18ff0",
   "metadata": {},
   "source": [
    "Below, you are given training and testing data that is visualized in matplotlib. Your job is to implement the KNN Algorithm using your `euc_distance` function so that we can predict the class for the black and green clusters of testing data, using our blue and red training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f882fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "mean1, cov1 = np.array([10,2]), np.array([[3,0],[5,3]]) \n",
    "mean2, cov2 = np.array([5,4]), np.array([[28,3],[3,20]]) \n",
    "cluster_1 = np.random.multivariate_normal(mean1, cov2, 100) \n",
    "cluster_2 = np.random.multivariate_normal(mean1, cov2, 100) + 10\n",
    "test_data_1 = np.random.multivariate_normal(mean1, cov1, 20) \n",
    "test_data_2 = np.random.multivariate_normal(mean2, cov2, 20) + 10\n",
    "test_data = np.random.multivariate_normal((mean1+mean2)/2, (cov1+cov2)/2, 100) + 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5c8a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,8), dpi=150)\n",
    "plt.scatter(cluster_1[:,0], cluster_1[:,1], label=\"Positive Class\")\n",
    "plt.scatter(cluster_2[:,0], cluster_2[:,1], label=\"Negative Class\", c='r')\n",
    "plt.scatter(test_data_1[:,0], test_data_1[:,1], label=\"Positive Test\", c='black')\n",
    "plt.scatter(test_data_2[:,0], test_data_2[:,1], label=\"Negative Test\", c='green')\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.title(\"k-NN Training and Testing Data\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efce500a",
   "metadata": {},
   "source": [
    "#### Implementation Instructions / Psuedocode:\n",
    "\n",
    "- Create a k-NN model that can take `k` number of neighbors to select for majority voting, `x_train` data points that comprise the model (the red and blue points), and `y_train` class labels corresponding to `x_train`, as an argument\n",
    "- Store the distance between each `x_test` data point and the training set into an array and sort it according to ascending order of their distances\n",
    "    - _Hint:_ `np.argsort` is useful\n",
    "- Select the first K elements\n",
    "- Perform majority voting so that the class with most occurences in the first K elements will be assigned as the new class for that test data point.\n",
    "    - _Hint:_ `mode` from scipy.stats may be useful\n",
    "- `return` a NumPy array of the labels generated with `x_test`\n",
    "\n",
    "\n",
    "_Points:_ 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be437ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "\n",
    "X_train = np.vstack((cluster_1, cluster_2))\n",
    "y_train = np.append(np.ones(len(cluster_1)), np.zeros(len(cluster_2))).reshape(len(cluster_1) + len(cluster_2), 1)\n",
    "x_test = np.vstack((test_data_1, test_data_2))\n",
    "y_test = np.append(np.ones(len(test_data_1)), np.zeros(len(test_data_2))).reshape(len(test_data_1) + len(test_data_2), 1)\n",
    "\n",
    "def predict(k, x_train, y_train, x_test):\n",
    "    \"\"\"\n",
    "    Input\n",
    "    -----\n",
    "    k: number of nearest neighbors\n",
    "    x_train: training data of x1,x2 coordinate positions. (n,2) numpy array \n",
    "    y_train: training data of class labels. (n,1) numpy array\n",
    "    y_test: testing data of x1, x2 coordinate positions. (n,2) numpy array\n",
    "    \n",
    "    \n",
    "    Output\n",
    "    -----\n",
    "    y_pred: predictions of which class all points in y_test belong to. (n,) numpy array\n",
    "    \n",
    "    \"\"\"\n",
    "    y_pred = []\n",
    "    \n",
    "    # Enter your implementation below\n",
    "    y_pred = np.array(y_pred)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def compute_accuracy(y_pred, y_test):\n",
    "    incorrect = np.count_nonzero(y_pred.flatten() != y_test.flatten())\n",
    "    accuracy = (1 - incorrect/len(y_test))\n",
    "    return accuracy\n",
    "    \n",
    "\n",
    "y_pred_k1 = predict(1, X_train, y_train,x_test)\n",
    "y_pred_k3 = predict(3, X_train, y_train,x_test)\n",
    "y_pred_k5 = predict(5, X_train, y_train,x_test)\n",
    "\n",
    "\n",
    "for k, predictions in zip([1,3,5],[y_pred_k1, y_pred_k3, y_pred_k5]):\n",
    "    accuracy = compute_accuracy(predictions, y_test) \n",
    "    print(f\"K = {k}: Accuracy = {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27c2fd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "scipy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbcc8d6",
   "metadata": {},
   "source": [
    "# End of A4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192a329f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit.\n",
    "\n",
    "Please make sure to see the output of the gradescope autograder. You are responsible for waiting and ensuring that the autograder is executing normally for your submission. Please create a campuswire post if you see errors in autograder execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6073124",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.export(pdf=False, force_save=True, run_tests=True, files=['imgs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49de4b08",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "KNN": {
     "name": "KNN",
     "points": 0.5,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "MCQ_1_1": {
     "name": "MCQ_1_1",
     "points": 0.15,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # sanity check\n>>> all_options = [\"A\", \"B\", \"C\", \"D\"]\n>>> check_valid = lambda ans, all_options: all([chosen in all_options for chosen in ans])\n>>> assert check_valid(q1_1, all_options), \"Is your answer within the option of A/B/C/D?\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "MCQ_1_2": {
     "name": "MCQ_1_2",
     "points": 0.15,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # sanity check\n>>> all_options = [\"A\", \"B\", \"C\", \"D\"]\n>>> check_valid = lambda ans, all_options: all([chosen in all_options for chosen in ans])\n>>> assert check_valid(q1_2, all_options), \"Is your answer within the option of A/B/C/D?\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "MCQ_1_3": {
     "name": "MCQ_1_3",
     "points": 0.15,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # sanity check\n>>> all_options = [\"A\", \"B\", \"C\", \"D\"]\n>>> check_valid = lambda ans, all_options: all([chosen in all_options for chosen in ans])\n>>> assert check_valid(q1_3, all_options), \"Is your answer within the option of A/B/C/D?\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "MCQ_4": {
     "name": "MCQ_4",
     "points": 0.3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # sanity check\n>>> all_options = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"]\n>>> check_valid = lambda ans, all_options: all([chosen in all_options for chosen in ans])\n>>> assert check_valid(q4, all_options), \"Is your answer within the option of A-H?\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "TF_3_1": {
     "name": "TF_3_1",
     "points": 0.15,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # sanity check\n>>> assert isinstance(q3_1, bool), \"your answer should be a boolean value (True or False)\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "TF_3_2": {
     "name": "TF_3_2",
     "points": 0.15,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # sanity check\n>>> assert isinstance(q3_2, bool), \"your answer should be a boolean value (True or False)\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "TF_3_3": {
     "name": "TF_3_3",
     "points": 0.15,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # sanity check\n>>> assert isinstance(q3_3, bool), \"your answer should be a boolean value (True or False)\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "TF_3_4": {
     "name": "TF_3_4",
     "points": 0.15,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # sanity check\n>>> assert isinstance(q3_4, bool), \"your answer should be a boolean value (True or False)\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "euclidean distance": {
     "name": "euclidean distance",
     "points": 0.2,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
