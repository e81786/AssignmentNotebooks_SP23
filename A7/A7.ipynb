{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3855bae",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"A7.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18413c8",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-68f2f0ed9883b594",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Assignment 7\n",
    "\n",
    "\n",
    "## **Due: May 24th (Wednesday), 2023, 8:00pm (PT)**\n",
    "\n",
    "### **Instructions:**\n",
    "\n",
    "Your Jupyter notebook assignment will often have 3 elements: written answers, code answers, and quiz answers. For written answers, you may insert images of your handwritten work in code cells, or write your answers in markdown and LaTeX. For quiz answers, your `record.txt` file will record your answer choices in the quiz modules for submission. Both your quiz answers and code answers will be autograded on Gradescope. This assignment does not have the quiz portion.\n",
    "\n",
    "For all elements, DO NOT MODIFY THE CELLS. Put your answers **only** in the answer cells given, and **do not delete cells**. If you fail to follow these instructions, you will lose points on your submission.\n",
    "\n",
    "Make sure to show the steps of your solution for every question to receive credit, not just the final answer. You may search information online but you will need to write code/find solutions to answer the questions yourself. You will submit your .ipynb file and record.txt to gradescope when you are finished.\n",
    "\n",
    "### **Late Policy:**\n",
    "\n",
    "Late assignments will be accepted at 75% credit up to 3 days late. Consult the syllabus for more info on the late policy.\n",
    "\n",
    "### How to Include Your Math Written Answer?\n",
    "\n",
    "You could use inline $\\LaTeX$ in markdown (recommended) or use markdowns' include image functionality to submit your written responses.\n",
    "\n",
    "#### $\\LaTeX$ (recommended)\n",
    "[Here is a fantastic tutorial from CalTech about using $\\LaTeX$ in Jupyter Notebook.](http://chebe163.caltech.edu/2018w/handouts/intro_to_latex.html). You could also find various $\\LaTeX$ tutorials and cheat sheets online.\n",
    "\n",
    "#### Include Images\n",
    "If you are still getting familiar with using LaTeX, handwrite the response on paper or the stylus. Take a picture or screenshot of your answer, and include that image in the Jupyter Notebook. Be sure to include that image in the `\\imgs` directory. Let's say you have your Q1 response saved as `imgs/Q1.png`; the markdown syntax to include that image is `![Q1](imgs/Q1.png)`. \n",
    "\n",
    "## Important Notice\n",
    "\n",
    "You must check both submission output on the gradescope (`Assignment 7` and `Assignment 7 - Manual Grading`) correctly reflects your work and responses. If you notice inconsistencies between your notebook and the Manual Grading portion, you need to make a campuswire post, and we can help you with that.\n",
    "\n",
    "**Other**\n",
    "\n",
    "If you are not feeling comfortable with the programming assignments in this homework, it might help to take a look at [https://github.com/UCSD-COGS108/Tutorials](https://github.com/UCSD-COGS108/Tutorials)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a145adb",
   "metadata": {},
   "source": [
    "# Question 1: Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bc7110",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Q1.1\n",
    "\n",
    "Suppose you have three classification models with test set accuracy of 60\\%, 80\\% and 90\\% respectively. If you use the **majority vote** ensemble method, what is the expected test set accuracy of the ensemble?\n",
    "\n",
    "_Points:_ 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464b33c6",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8668aae",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Q1.2\n",
    "Suppose we have an ensemble of three classifiers A, B, and C that predict the labels of a binary classification problem. Each classifier predicts the positive label with probability 0.8 and the negative label with probability 0.2.\n",
    "    \n",
    "To make the final prediction, we will use **soft voting** with default weighting. What is the probability that the ensemble predicts the positive label?\n",
    "\n",
    "_Points:_ 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54e3278",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7053539",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# Question 2 Boosting\n",
    "\n",
    "Consider using AdaBoost algorithm to do binary classification on a toy dataset as follows.\n",
    "\n",
    "|   | feature a | feature b | feature c | label |\n",
    "|---|-----------|-----------|-----------|-------|\n",
    "| A | 15        | 42        | 1         | T     |\n",
    "| B | 11        | 30        | 1         | T     |\n",
    "| C | 17        | 20        | 0         | T     |\n",
    "| D | 22        | 25        | 0         | F     |\n",
    "| E | 15        | 27        | 1         | F     |\n",
    "| F | 19        | 43        | 1         | F     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3629b2b9",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Q2.1\n",
    "\n",
    "Consider the following 3 weak classifiers:\n",
    "\n",
    "$$h_a(x) = sign(x_a \\leq th_a)$$\n",
    "$$h_b(x) = sign(x_b \\leq th_b)$$\n",
    "$$h_c(x) = sign(x_c \\geq th_c)$$\n",
    "\n",
    "What should be the **smallest integer** value of $th_a$, $th_b$ and $th_c$ to minimize the misclassification error?\n",
    "\n",
    "_Points:_ 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d76ab6",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a83ad15",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Q2.2\n",
    "\n",
    "Gini impurity measures the quality of a split. Consider a dataset D that contains samples from k classes. For a given node $m$, suppose the probability of samples from D belonging to class j is $p_{j}$. Then the Gini Impurity of this node is: \n",
    "\n",
    "$$Gini_m(D) = 1 - \\sum_{j=1}^{k} p_j^2$$\n",
    "\n",
    "A binary split (e.g. $h(x)=sign(x \\leq th)$) consists of two nodes (e.g.: $x \\leq th$ and $x > th$). Suppose after the split a dataset $D$ (of size $n$) is divided into two subsets ($D_1$ of size $n_1$ and $D_2$ of size $n_2$, corresponding to node $m_1$ and $m_2$ respectively). Therefore the Gini impurity of this split is\n",
    "\n",
    "$$Gini(s, D) = \\frac{n_1}{n} Gini_{m_1}(D_1) + \\frac{n_2}{n} Gini_{m_2}(D_2)$$\n",
    "\n",
    "What is the Gini impurity of $h_a$? \n",
    "\n",
    "(Give your answer in fraction)\n",
    "\n",
    "_Points:_ 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f613a4b0",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f600fa9",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Q2.3\n",
    "\n",
    "The one that yields the lowest misclassification error among the 3 classifiers $h_a$, $h_b$ and $h_c$ is selected as $h_1$ in the first iteration of running AdaBoost algorithm.\n",
    "\n",
    "(1) During the first iteration, what is the weighted error rate $\\epsilon_1$? What is $\\alpha_1=\\frac{1}{2}\\ln (\\frac{1 - \\epsilon_1}{\\epsilon_1})$? \n",
    "\n",
    "(Give your answer to three decimal places.) \n",
    "\n",
    "_Points:_ 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937a70cf",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919610c2",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "(2) After the first iteration of update, what is the weight of sample A and E respectively? \n",
    "\n",
    "(Give your answer to three decimal places.) \n",
    "\n",
    "_Points:_ 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a2a498",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a281375c",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# End of A7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6143d384",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit.\n",
    "\n",
    "Please make sure to see the output of the gradescope autograder. You are responsible for waiting and ensuring that the autograder is executing normally for your submission. Please create a campuswire post if you see errors in autograder execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e219eec",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.export(pdf=False, force_save=True, run_tests=True, files=['imgs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49c1234",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
